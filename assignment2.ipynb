{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "098b2971-5d7a-4d7f-aec2-3400a31a72b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Think I'm going to start with a boosted model. Might overfit, but Dusty said that it was good with \"toy data\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "data = pd.read_csv(\"https://github.com/dustywhite7/Econ8310/raw/master/AssignmentData/assignment3test.csv\")\n",
    "\n",
    "data = data.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "9f4325b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'DateTime', 'Total', 'Discounts', 'Brewed_Coffee_12_oz',\n",
      "       'Brewed_Coffee_16_oz', 'Aquafina_Water', 'Muffin_Pastry_Case',\n",
      "       'Extra_Syrup', 'Bottled_Soda_Mt_Dew', 'Bottled_Soda_Diet_Pepsi',\n",
      "       'Latte_16_oz', 'Latte_12_oz', 'Original', 'String_Cheese',\n",
      "       'Soda_Fountain_24_oz', 'Starbucks_DS_Vanilla',\n",
      "       'Bottled_Soda_Wild_Cherry', 'Gatorade_Glacier_Freeze',\n",
      "       'TeaSmith_Tea_16_oz', 'Iced', 'Bottled_Soda_Diet_Mt_Dew',\n",
      "       'Candy_Snickers', 'Tea_Unsweetened', 'Bottled_Soda_Code_Red',\n",
      "       'Chips_Kettle_Jalapeo', 'Chex_Mix_Traditional', 'Rockstar_Zero_Punched',\n",
      "       'Ocean_Spray_Apple', 'Americano_16_oz', 'TeaSmith_Tea_12_oz',\n",
      "       'Tea_Half_and_Half', 'Chips_Kettle_Sea_Salt', 'Mocha_16_oz',\n",
      "       'Nuts_Cashews', 'Chips_Kettle_BBQ', 'Tea_Sweetened', 'Gatorade_Orange',\n",
      "       'Chex_Mix_Cheddar', 'Candy_KitKat', 'Parfait_Strawberry',\n",
      "       'Gatorade_Cool_Blue', 'Cheez_It_Original', 'Bottled_Soda_Pepsi',\n",
      "       'Nuts_Hot_n_Spicy_Peanuts', 'Candy_Peanut_Butter_MM's',\n",
      "       'Ocean_Spray_Orange', 'Kickstart_Raspberry', 'Kickstart_Orange',\n",
      "       'Candy_Reeses', 'Extra_Espresso',\n",
      "       'Clif_Bar_White_Chocolate_Macadamia_Nut', 'Candy_Twix',\n",
      "       'Western's_Jerky_Beef', 'Pringles_Original', 'Nuts_Salted_Peanuts',\n",
      "       'Pringles_Sour_Cream_Onion', 'Chocolate_Muscle_Milk',\n",
      "       'Kickstart_Pineapple_Orange_Mango', 'MM', 'Turtle_16_oz',\n",
      "       'Kickstart_Grape', 'Parfait_Blueberry', 'Moroccan_Mint',\n",
      "       'SoBe_Life_Acai', 'White_Mocha_16_oz', 'Gum_Spearmint',\n",
      "       'Kickstart_Mango_Lime', 'Clif_Bar_Brownie_Bar',\n",
      "       'Cheez_It_White_Cheddar', 'Starbucks_Mocha_Frap',\n",
      "       'Gatorade_Fruit_Punch', 'Hot_Chocolate_12_oz', 'Cup',\n",
      "       'Sweet_Pomegranate', 'Gatorade_Grape', 'White_Mocha_12_oz',\n",
      "       'Whipped_Topping', 'Starbucks_DS_Mocha', 'Hot_Chocolate_16_oz',\n",
      "       'Dr_Pepper', 'Ocean_Spray_CranGrape', 'Gum_Peppermint', 'meal'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5887373",
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "[15:30:26] C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\objective\\./regression_loss.h:68: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[157], line 21\u001b[0m\n\u001b[0;32m     11\u001b[0m model \u001b[38;5;241m=\u001b[39m XGBClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2000\u001b[39m, \n\u001b[0;32m     12\u001b[0m                       max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m, \n\u001b[0;32m     13\u001b[0m                       learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.4\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m                       objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary:logistic\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     17\u001b[0m                       eval_metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogloss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     19\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m---> 21\u001b[0m modelFit \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(x, y)\n\u001b[0;32m     24\u001b[0m pred1 \u001b[38;5;241m=\u001b[39m modelFit\u001b[38;5;241m.\u001b[39mpredict(xt)\n\u001b[0;32m     25\u001b[0m pred \u001b[38;5;241m=\u001b[39m pred1\u001b[38;5;241m.\u001b[39mflatten()\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[1;32mc:\\Users\\jared\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jared\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py:1683\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[0;32m   1661\u001b[0m model, metric, params, feature_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(\n\u001b[0;32m   1662\u001b[0m     xgb_model, params, feature_weights\n\u001b[0;32m   1663\u001b[0m )\n\u001b[0;32m   1664\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1665\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[0;32m   1666\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1680\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[0;32m   1681\u001b[0m )\n\u001b[1;32m-> 1683\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m train(\n\u001b[0;32m   1684\u001b[0m     params,\n\u001b[0;32m   1685\u001b[0m     train_dmatrix,\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_num_boosting_rounds(),\n\u001b[0;32m   1687\u001b[0m     evals\u001b[38;5;241m=\u001b[39mevals,\n\u001b[0;32m   1688\u001b[0m     early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mearly_stopping_rounds,\n\u001b[0;32m   1689\u001b[0m     evals_result\u001b[38;5;241m=\u001b[39mevals_result,\n\u001b[0;32m   1690\u001b[0m     obj\u001b[38;5;241m=\u001b[39mobj,\n\u001b[0;32m   1691\u001b[0m     custom_metric\u001b[38;5;241m=\u001b[39mmetric,\n\u001b[0;32m   1692\u001b[0m     verbose_eval\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   1693\u001b[0m     xgb_model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m   1694\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks,\n\u001b[0;32m   1695\u001b[0m )\n\u001b[0;32m   1697\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[0;32m   1698\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\jared\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jared\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 183\u001b[0m bst\u001b[38;5;241m.\u001b[39mupdate(dtrain, iteration\u001b[38;5;241m=\u001b[39mi, fobj\u001b[38;5;241m=\u001b[39mobj)\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jared\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:2246\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   2243\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[0;32m   2245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2246\u001b[0m     _check_call(\n\u001b[0;32m   2247\u001b[0m         _LIB\u001b[38;5;241m.\u001b[39mXGBoosterUpdateOneIter(\n\u001b[0;32m   2248\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, ctypes\u001b[38;5;241m.\u001b[39mc_int(iteration), dtrain\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   2249\u001b[0m         )\n\u001b[0;32m   2250\u001b[0m     )\n\u001b[0;32m   2251\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2252\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\jared\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:310\u001b[0m, in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[0;32m    300\u001b[0m \n\u001b[0;32m    301\u001b[0m \u001b[38;5;124;03mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;124;03m    return value from API calls\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[38;5;241m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[1;31mXGBoostError\u001b[0m: [15:30:26] C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\objective\\./regression_loss.h:68: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 0"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "Y = data['meal']\n",
    "# make sure you drop a column with the axis=1 argument\n",
    "columns_to_drop = ['id', 'DateTime', 'meal', 'Discounts', 'Total']\n",
    "X = data.drop(columns=columns_to_drop, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "x, xt, y, yt = train_test_split(X, Y, test_size=.2, random_state=67) \n",
    "\n",
    "\n",
    "model = XGBClassifier(n_estimators=2000, \n",
    "                      max_depth=12, \n",
    "                      learning_rate=0.4,\n",
    "                      gamma=1, #this punishes super complex models\n",
    "                      min_child_weight=5,\n",
    "                      objective='binary:logistic', \n",
    "                      eval_metric = 'logloss')\n",
    "\n",
    "\n",
    "modelFit = model.fit(x, y)\n",
    "\n",
    "\n",
    "pred1 = modelFit.predict(xt)\n",
    "pred = pred1.flatten().tolist()\n",
    "\n",
    "\n",
    "\n",
    "print(accuracy_score(yt, pred)*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "73b445d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
